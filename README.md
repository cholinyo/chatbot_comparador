# ğŸ§  Chatbot Comparador RAG

Este proyecto Flask permite comparar respuestas generadas por dos modelos de lenguaje (uno local y otro de OpenAI) usando RAG (Retrieval-Augmented Generation). AdemÃ¡s, ofrece un chat conversacional que accede a fuentes mÃºltiples: documentos, pÃ¡ginas web, APIs y bases de datos.

---

## ğŸ“¦ Estructura del Proyecto

```
chatbot_comparador/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routes/                  # Blueprints Flask (chat, config, comparador)
â”‚   â”œâ”€â”€ services/                # Ingestores e interfaces con modelos
â”‚   â”œâ”€â”€ utils/                   # Utilidades (RAG, validaciones, etc)
â”‚   â”œâ”€â”€ templates/               # Plantillas HTML (Jinja2)
â”‚   â”œâ”€â”€ config/settings.json     # ConfiguraciÃ³n de fuentes RAG
â”‚   â””â”€â”€ static/
â”œâ”€â”€ vectorstore/
â”‚   â”œâ”€â”€ documents/               # Ãndices FAISS de documentos
â”‚   â”œâ”€â”€ web/                     # Ãndices FAISS de URLs
â”‚   â”œâ”€â”€ apis/                    # Ãndices FAISS de APIs
â”‚   â””â”€â”€ bbdd/                    # Ãndices FAISS de bases de datos
â””â”€â”€ run.py                       # Lanzador principal
```

---

## âš™ï¸ Funcionalidades

### ğŸ”„ Comparador
Accede a `/comparar` y realiza una pregunta. ObtendrÃ¡s dos respuestas:
- ğŸ§  Modelo Local (por defecto)
- â˜ï¸ OpenAI (si estÃ¡ disponible)

Cada respuesta se basa en la recuperaciÃ³n contextual usando FAISS.

### ğŸ’¬ Chat Unificado
Accede a `/chat` para preguntar sobre cualquier fuente indexada:
- Recupera fragmentos por relevancia desde documentos, URLs, APIs y bases de datos.
- Se muestra la fuente, la distancia FAISS y el contenido.
- Solo se usa el modelo **local** para generar la respuesta.

### ğŸ§  IngestiÃ³n RAG por fuentes

Puedes configurar y lanzar la ingestiÃ³n desde:
```
http://127.0.0.1:5000/config
```

AllÃ­ puedes aÃ±adir:
- ğŸ“„ Carpetas de documentos (PDF, DOCX, TXT)
- ğŸŒ URLs individuales (con profundidad)
- ğŸ”Œ APIs configurables (con o sin autenticaciÃ³n)
- ğŸ—ƒï¸ Consultas a bases de datos (SQLite u otras)

### âœ¨ Sistema de vectorizaciÃ³n

- Se utiliza `SentenceTransformers` con `all-MiniLM-L6-v2`
- Se crean Ã­ndices independientes para cada tipo de fuente
- Cada fuente se guarda en su carpeta dentro de `vectorstore/`
- Se utilizan archivos:
  - `index.faiss`
  - `fragmentos.pkl`

---

## ğŸš« Clave OpenAI no configurada

Actualmente, el sistema **funciona con modelo local por defecto**.  
Si deseas usar OpenAI, aÃ±ade tu clave en un archivo `.env` como:

```bash
OPENAI_API_KEY=sk-xxx
```

---

## ğŸ§ª Scripts de ingestiÃ³n

Puedes ejecutar directamente:

```bash
python -m app.services.ingest_documents
python -m app.services.ingest_web
# futuros: ingest_api.py, ingest_bbdd.py
```

---

## ğŸ“‹ Requisitos

- Python 3.9+
- Selenium
- FAISS
- SentenceTransformers
- Flask
- webdriver-manager
- unstructured (para PDF)

InstalaciÃ³n recomendada:

```bash
pip install -r requirements.txt
```

---

## ğŸ› ï¸ Pendiente / Futuro

- Ingesta automatizada por dominio completo
- Historial de preguntas/respuestas
- Interfaz para exploraciÃ³n del vectorstore
- MigraciÃ³n completa a uso de modelos locales y fallback a OpenAI si se desea

---

## ğŸ“„ Licencia

MIT